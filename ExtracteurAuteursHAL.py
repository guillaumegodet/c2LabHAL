import requests
import pandas as pd
import time
import streamlit as st
from urllib.parse import urlencode

# Le point d'entr√©e de l'API de recherche HAL pour les documents
HAL_SEARCH_API = "http://api.archives-ouvertes.fr/search/"
# Le point d'entr√©e de l'API de r√©f√©rence HAL pour les auteurs (pour les d√©tails)
HAL_AUTHOR_API = "http://api.archives-ouvertes.fr/ref/author/"

# --- Fonctions d'extraction HAL (Adapt√©es √† la Collection) ---

def fetch_publications_for_collection(collection_code, years="", fields="structHasAuthId_fs"):
    """
    R√©cup√®re tous les documents (publications) pour un code de collection donn√©
    en utilisant l'API de recherche HAL.
    """
    all_docs = []
    rows = 10000  # Nombre maximal de documents par requ√™te
    start = 0
    
    # La requ√™te utilise le code de collection dans le chemin de l'URL pour un ciblage pr√©cis
    query_params = {
        'q': '*:*',
        'wt': 'json',
        'fl': fields,
        'rows': rows
    }

    if years:
        query_params['fq'] = f'producedDateY_i:{years}'
        
    st.toast(f"D√©marrage de la r√©cup√©ration pour la collection '{collection_code}' (Ann√©e(s): {years if years else 'Toutes'})")

    while True:
        query_params['start'] = start
        
        # URL de l'API de recherche HAL, avec le code de collection dans le chemin
        url = f"{HAL_SEARCH_API}{collection_code}/?{urlencode(query_params)}"
        
        try:
            response = requests.get(url)
            response.raise_for_status()
            data = response.json()
            
            docs = data.get('response', {}).get('docs', [])
            num_found = data.get('response', {}).get('numFound', 0)
            all_docs.extend(docs)
            
            found_publications = len(all_docs)
            
            if found_publications >= num_found or not docs:
                break
            
            start += rows
            time.sleep(0.5) 

        except requests.exceptions.RequestException as e:
            st.error(f"Erreur lors de la requ√™te API (Recherche publications): {e}")
            break
            
    return all_docs

def extract_author_ids(publications):
    """
    Extrait les identifiants uniques des formes-auteurs (docid du r√©f√©rentiel auteur)
    √† partir de la liste des publications.
    """
    author_ids = set()
    for doc in publications:
        authors = doc.get('structHasAuthId_fs', [])
        for author_str in authors:
            # Le format est typiquement "STRUCTID_HALID_JoinSep_AUTHORID_FacetSep"
            parts = author_str.split('_JoinSep_')
            if len(parts) > 1:
                # Capture de l'ID de la forme-auteur (ce qui correspond au docid dans /ref/author)
                author_id_part = parts[1].split('_FacetSep')[0]
                author_ids.add(author_id_part)
                
    return list(author_ids)

def fetch_author_details(author_ids, fields):
    """
    R√©cup√®re les d√©tails de chaque forme-auteur (par son docid)
    en utilisant l'API de r√©f√©rence HAL.
    """
    authors_details = []
    chunk_size = 50 
    total_authors = len(author_ids)
    
    st.toast(f"R√©cup√©ration des d√©tails pour {total_authors} formes-auteurs...")
    
    for i in range(0, total_authors, chunk_size):
        chunk = author_ids[i:i + chunk_size]
        # Construction de la requ√™te Solr pour les docid
        docid_query = '%22 OR docid:%22'.join(chunk)
        
        query_params = {
            'q': f'docid:"{docid_query}"',
            'wt': 'json',
            'fl': fields
        }
        
        url = f"{HAL_AUTHOR_API}?{urlencode(query_params)}"
        
        try:
            response = requests.get(url)
            response.raise_for_status()
            data = response.json()
            
            docs = data.get('response', {}).get('docs', [])
            
            # Application de la logique de transformation du statut de validation (comme dans le script JS original)
            for doc in docs:
                if 'valid_s' in doc:
                    validity_status = doc['valid_s']
                    if validity_status == "VALID":
                        doc['valid_s'] = "forme auteur principale d'un IdHAL"
                    elif validity_status == "OLD":
                        doc['valid_s'] = "forme auteur alternative d'un IdHAL"
                    elif validity_status == "INCOMING":
                        doc['valid_s'] = "forme auteur sans IdHAL associ√©"
                authors_details.append(doc)

            time.sleep(0.3) 

        except requests.exceptions.RequestException as e:
            st.error(f"Erreur lors de la requ√™te API (D√©tails Auteur): {e}")
            break
            
    return authors_details

def get_all_author_forms_data(collection_code, years="", fields_list="docid,fullName_s,valid_s,halId_s,orcidId_s,firstName_s,lastName_s"):
    """
    Fonction principale pour orchestrer l'extraction de TOUTES les formes-auteurs 
    (sans d√©duplication) pour une collection.
    """
    
    # 1. R√©cup√©rer les publications et les identifiants d'auteurs
    publications = fetch_publications_for_collection(collection_code, years)
    
    # --- AJOUT DE D√âBOGAGE 1 ---
    print(f"DEBUG: Nombre de publications trouv√©es par l'API: {len(publications)}")
    # --- FIN D√âBOGAGE 1 ---
    
    if not publications:
        return pd.DataFrame()
        
    author_ids = extract_author_ids(publications)

    # --- AJOUT DE D√âBOGAGE 2 ---
    print(f"DEBUG: Nombre d'IDs de formes-auteurs extraits des publications: {len(author_ids)}")
    # --- FIN D√âBOGAGE 2 ---
    
    if not author_ids:
        st.info("Aucune forme-auteur trouv√©e pour la collection et l'ann√©e(s) sp√©cifi√©es.")
        return pd.DataFrame()

    # 2. R√©cup√©rer les d√©tails des auteurs (formes-auteurs)
    author_details = fetch_author_details(author_ids, fields_list)

    if not author_details:
        return pd.DataFrame()

    # 3. Cr√©er le DataFrame final (pas de d√©duplication)
    df = pd.DataFrame(author_details)
    
    # S'assurer que les colonnes sont dans l'ordre demand√©
    requested_fields = fields_list.split(',')
    final_cols = [col for col in requested_fields if col in df.columns]
    
    return df[final_cols]

# --- Fonctions utilitaires pour Streamlit ---
@st.cache_data
def convert_df(df):
    """Convertit un DataFrame en CSV pour le t√©l√©chargement."""
    # Utilisation du point-virgule comme s√©parateur pour la compatibilit√© Excel en fran√ßais
    return df.to_csv(index=False, sep=';').encode('utf-8')

def build_fields_list(fields_selected):
    """Construit la cha√Æne de champs √† partir des s√©lections Streamlit."""
    # Ajoute les champs obligatoires pour l'affichage
    mandatory_fields = ['docid', 'fullName_s', 'valid_s']
    
    final_fields = list(set(mandatory_fields + fields_selected))
    
    return ','.join(final_fields)

# --- Application Streamlit ---
def main():
    st.set_page_config(page_title="Extracteur Formes-Auteurs HAL (Collection)", layout="wide")
    st.title("Extracteur de Formes-Auteurs par Collection HAL")
    st.markdown("Extrait **toutes les formes-auteurs** rattach√©es aux publications de la collection. Utile pour l'identification des doublons.")

    # Options des champs (similaire aux champs courants du r√©f√©rentiel)
    all_available_fields = [
        'halId_s', 'orcidId_s', 'firstName_s', 'lastName_s', 
        'email_s', 'hasCV_bool', 'birthDateY_i'
    ]
    
    with st.sidebar:
        st.header("Param√®tres de l'Extraction")
        collection_code = st.text_input("Code Collection HAL (ex: CRAO, LEMNA)", value="LEMNA")
        years = st.text_input("P√©riode vis√©e (ex: [2016 TO 2018], 2023)", value="")
        
        st.subheader("Champs d'Auteur √† R√©cup√©rer")
        
        default_fields = ['halId_s', 'orcidId_s', 'firstName_s', 'lastName_s']
        
        fields_selected = st.multiselect(
            "S√©lectionnez les champs additionnels (le 'docid' est l'ID de la forme-auteur)", 
            options=all_available_fields,
            default=default_fields
        )
        
        # Bouton d'extraction
        if st.button("Lancer l'Extraction", type="primary"):
            if not collection_code:
                st.sidebar.error("Veuillez entrer un code de collection HAL.")
                return
            
            # Pr√©parer les champs pour l'API
            api_fields = build_fields_list(fields_selected)
            
            with st.spinner(f"R√©cup√©ration en cours pour la collection **{collection_code}**..."):
                # Ex√©cution de la logique d'extraction sans d√©duplication
                df_authors = get_all_author_forms_data(collection_code, years, api_fields)
            
            if df_authors.empty:
                st.warning("Aucun r√©sultat trouv√© pour cette collection et ces crit√®res.")
            else:
                st.session_state['df_authors'] = df_authors
                st.session_state['collection_code'] = collection_code
                st.session_state['years'] = years

    # --- Affichage des r√©sultats ---
    if 'df_authors' in st.session_state and not st.session_state['df_authors'].empty:
        df_authors = st.session_state['df_authors']
        collection_code = st.session_state['collection_code']
        years = st.session_state['years']
        
        st.subheader(f"R√©sultats pour Collection : **{collection_code}** ({'Ann√©e(s) : **' + years + '**' if years else '**Toutes ann√©es**'})")
        
        # L'affichage des doublons est utile pour rep√©rer les doublons par nom
        df_display = df_authors.sort_values(by='fullName_s') 
        
        st.info(f"Nombre total de **formes-auteurs** trouv√©es : **{len(df_authors)}**")
        st.markdown("_Les lignes ayant le m√™me `fullName_s` mais un `docid` (ID de forme-auteur) diff√©rent sont des doublons potentiels._")
        
        # Afficher le DataFrame
        st.dataframe(df_display, use_container_width=True)
        
        # Pr√©parer et afficher le bouton de t√©l√©chargement CSV
        csv_data = convert_df(df_authors)
        filename = f'toutes_formes_auteurs_{collection_code}_{years.replace(" ", "_") if years else "all"}.csv'
        
        st.download_button(
            label="üíæ T√©l√©charger la liste de TOUTES les formes-auteurs (CSV)",
            data=csv_data,
            file_name=filename,
            mime='text/csv',
            key='download_button'
        )
        st.markdown("_Le s√©parateur est le point-virgule (`;`) pour Excel._")

if __name__ == '__main__':
    main()
