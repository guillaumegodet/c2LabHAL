import os # Pour la variable d'environnement NCBI_API_KEY
import streamlit as st
import pandas as pd
import io
# SupprimÃ©: requests, json, unicodedata, difflib, tqdm, concurrent
# Ces imports sont maintenant dans utils.py ou non nÃ©cessaires directement ici

# Importer les fonctions et constantes partagÃ©es depuis utils.py
from utils import (
    get_scopus_data, get_openalex_data, get_pubmed_data, convert_to_dataframe,
    clean_doi, HalCollImporter, merge_rows_with_sources, get_authors_from_crossref,
    check_df, enrich_w_upw_parallel, add_permissions_parallel, deduce_todo,
    normalise, normalize_name, get_initial_form # normalise est utilisÃ© par HalCollImporter et check_df
)
# Les constantes comme HAL_API_ENDPOINT sont utilisÃ©es par les fonctions dans utils.py

# --- DÃ©finition de la liste des laboratoires (spÃ©cifique Ã  cette application) ---
labos_list_nantes = [
    {
        "collection": "METIS", "scopus_id": "60105490", "openalex_id": "I4387152714",
        "pubmed_query": "(CAPHI[Affiliation]) OR (\"CENTRE ATLANTIQUE DE PHILOSOPHIE\"[Affiliation]) OR (\"EA 7463\" [Affiliation]) OR (EA7463[Affiliation]) OR (UR7463[Affiliation]) OR (\"UR 7463\"[Affiliation])"
    }
]
labos_df_nantes_global = pd.DataFrame(labos_list_nantes)


# Fonction pour ajouter le menu de navigation (spÃ©cifique Ã  cette app)
def add_sidebar_menu():
    st.sidebar.header("Ã€ Propos")
    st.sidebar.info(
    """
    **c2LabHAL - Version Nantes UniversitÃ©** :
    Cette version est prÃ©configurÃ©e pour les laboratoires de Nantes UniversitÃ©.
    SÃ©lectionnez un laboratoire dans la liste pour lancer la comparaison de ses publications
    (Scopus, OpenAlex, PubMed) avec sa collection HAL.
    """
)
    st.sidebar.markdown("---")

    st.sidebar.header("Autres applications c2LabHAL")
    st.sidebar.markdown("ðŸ“– [c2LabHAL - Application Principale](https://c2labhal.streamlit.app/)")
    st.sidebar.markdown("ðŸ“„ [c2LabHAL version CSV](https://c2labhal-csv.streamlit.app/)")


    st.sidebar.markdown("---")
    
    st.sidebar.markdown("PrÃ©sentation du projet :")
    st.sidebar.markdown("[ðŸ“Š Voir les diapositives](https://slides.com/guillaumegodet/deck-d5bc03#/2)")
    st.sidebar.markdown("Code source :")
    st.sidebar.markdown("[ðŸ™ Voir sur GitHub](https://github.com/GuillaumeGodet/c2labhal)")


def main():
    st.set_page_config(page_title="c2LabHAL - Nantes", layout="wide")
    add_sidebar_menu() 

    st.title("ðŸ¥Ž c2LabHAL - Version Nantes UniversitÃ©")
    st.subheader("Comparez les publications dâ€™un laboratoire de Nantes UniversitÃ© avec sa collection HAL.")

    labo_choisi_nom_nantes = st.selectbox(
        "Choisissez une collection HAL de laboratoire (Nantes UniversitÃ©) :", 
        sorted(labos_df_nantes_global['collection'].unique())
    )

    labo_selectionne_details_nantes = labos_df_nantes_global[labos_df_nantes_global['collection'] == labo_choisi_nom_nantes].iloc[0]
    collection_a_chercher_nantes = labo_selectionne_details_nantes['collection']
    scopus_lab_id_nantes = labo_selectionne_details_nantes.get('scopus_id', '') 
    openalex_institution_id_nantes = labo_selectionne_details_nantes.get('openalex_id', '')
    pubmed_query_labo_nantes = labo_selectionne_details_nantes.get('pubmed_query', '')

    scopus_api_key_secret_nantes = st.secrets.get("SCOPUS_API_KEY")
    pubmed_api_key_secret_nantes = st.secrets.get("PUBMED_API_KEY")

    col1_dates_nantes, col2_dates_nantes = st.columns(2)
    with col1_dates_nantes:
        start_year_nantes = st.number_input("AnnÃ©e de dÃ©but", min_value=1900, max_value=2100, value=2020, key="nantes_start_year")
    with col2_dates_nantes:
        end_year_nantes = st.number_input("AnnÃ©e de fin", min_value=1900, max_value=2100, value=pd.Timestamp.now().year, key="nantes_end_year")

    with st.expander("ðŸ”§ Options avancÃ©es pour les auteurs"):
        fetch_authors_nantes = st.checkbox("ðŸ§‘â€ðŸ”¬ RÃ©cupÃ©rer les auteurs via Crossref (peut ralentir)", value=False, key="nantes_fetch_authors_cb")
        compare_authors_nantes = False
        uploaded_authors_file_nantes = None
        if fetch_authors_nantes:
            compare_authors_nantes = st.checkbox("ðŸ” Comparer les auteurs avec une liste de chercheurs", value=False, key="nantes_compare_authors_cb")
            if compare_authors_nantes:
                uploaded_authors_file_nantes = st.file_uploader(
                    "ðŸ“¤ TÃ©lÃ©versez un fichier CSV de chercheurs (colonnes: 'collection', 'prÃ©nom nom')", 
                    type=["csv"], 
                    key="nantes_upload_authors_fu",
                    help="Le fichier CSV doit avoir une colonne 'collection' (code de la collection HAL) et une colonne avec les noms des chercheurs."
                )
    
    progress_bar_nantes = st.progress(0)
    progress_text_area_nantes = st.empty() # Correction: Suffixe _nantes ajoutÃ©

    if st.button(f"ðŸš€ Lancer la recherche pour {collection_a_chercher_nantes}"):
        if pubmed_api_key_secret_nantes and pubmed_query_labo_nantes:
            os.environ['NCBI_API_KEY'] = pubmed_api_key_secret_nantes

        scopus_df_nantes = pd.DataFrame()
        openalex_df_nantes = pd.DataFrame()
        pubmed_df_nantes = pd.DataFrame()

        # --- Ã‰tape 1 : RÃ©cupÃ©ration OpenAlex ---
        if openalex_institution_id_nantes:
            with st.spinner(f"RÃ©cupÃ©ration OpenAlex pour {collection_a_chercher_nantes}..."):
                progress_text_area_nantes.info("Ã‰tape 1/9 : RÃ©cupÃ©ration des donnÃ©es OpenAlex...") # CorrigÃ©
                progress_bar_nantes.progress(5) # CorrigÃ©
                openalex_query_complet_nantes = f"authorships.institutions.id:{openalex_institution_id_nantes},publication_year:{start_year_nantes}-{end_year_nantes}"
                openalex_data_nantes = get_openalex_data(openalex_query_complet_nantes, max_items=5000)
                if openalex_data_nantes:
                    openalex_df_nantes = convert_to_dataframe(openalex_data_nantes, 'openalex')
                    openalex_df_nantes['Source title'] = openalex_df_nantes.apply(
                        lambda row: row.get('primary_location', {}).get('source', {}).get('display_name') if isinstance(row.get('primary_location'), dict) and row['primary_location'].get('source') else None, axis=1
                    )
                    openalex_df_nantes['Date'] = openalex_df_nantes.get('publication_date', pd.Series(index=openalex_df_nantes.index, dtype='object'))
                    openalex_df_nantes['doi'] = openalex_df_nantes.get('doi', pd.Series(index=openalex_df_nantes.index, dtype='object'))
                    openalex_df_nantes['id'] = openalex_df_nantes.get('id', pd.Series(index=openalex_df_nantes.index, dtype='object'))
                    openalex_df_nantes['Title'] = openalex_df_nantes.get('title', pd.Series(index=openalex_df_nantes.index, dtype='object'))
                    cols_to_keep_nantes = ['Data source', 'Title', 'doi', 'id', 'Source title', 'Date']
                    openalex_df_nantes = openalex_df_nantes[[col for col in cols_to_keep_nantes if col in openalex_df_nantes.columns]]
                    if 'doi' in openalex_df_nantes.columns:
                        openalex_df_nantes['doi'] = openalex_df_nantes['doi'].apply(clean_doi)
                st.success(f"{len(openalex_df_nantes)} publications OpenAlex trouvÃ©es pour {collection_a_chercher_nantes}.")
        progress_bar_nantes.progress(10) # CorrigÃ©

        # --- Ã‰tape 2 : RÃ©cupÃ©ration PubMed ---
        if pubmed_query_labo_nantes: 
            with st.spinner(f"RÃ©cupÃ©ration PubMed pour {collection_a_chercher_nantes}..."):
                progress_text_area_nantes.info("Ã‰tape 2/9 : RÃ©cupÃ©ration des donnÃ©es PubMed...") # CorrigÃ©
                progress_bar_nantes.progress(20) # CorrigÃ© (ajustÃ© pour Ãªtre aprÃ¨s l'info)
                pubmed_full_query_nantes = f"({pubmed_query_labo_nantes}) AND ({start_year_nantes}/01/01[Date - Publication] : {end_year_nantes}/12/31[Date - Publication])"
                pubmed_data_nantes = get_pubmed_data(pubmed_full_query_nantes, max_items=5000)
                if pubmed_data_nantes:
                    pubmed_df_nantes = pd.DataFrame(pubmed_data_nantes)
                st.success(f"{len(pubmed_df_nantes)} publications PubMed trouvÃ©es pour {collection_a_chercher_nantes}.")
        else:
            st.info(f"Aucune requÃªte PubMed configurÃ©e pour {collection_a_chercher_nantes}.")
        progress_bar_nantes.progress(20) # CorrigÃ© (ou 25 si on veut marquer la fin de l'Ã©tape)

        # --- Ã‰tape 3 : RÃ©cupÃ©ration Scopus ---
        if scopus_lab_id_nantes and scopus_api_key_secret_nantes:
            with st.spinner(f"RÃ©cupÃ©ration Scopus pour {collection_a_chercher_nantes}..."):
                progress_text_area_nantes.info("Ã‰tape 3/9 : RÃ©cupÃ©ration des donnÃ©es Scopus...") # CorrigÃ©
                progress_bar_nantes.progress(25) # CorrigÃ© (ajustÃ©)
                scopus_query_complet_nantes = f"AF-ID({scopus_lab_id_nantes}) AND PUBYEAR > {start_year_nantes - 1} AND PUBYEAR < {end_year_nantes + 1}"
                scopus_data_nantes = get_scopus_data(scopus_api_key_secret_nantes, scopus_query_complet_nantes, max_items=5000)
                if scopus_data_nantes:
                    scopus_df_raw_nantes = convert_to_dataframe(scopus_data_nantes, 'scopus')
                    required_scopus_cols_nantes = {'dc:title', 'prism:doi', 'dc:identifier', 'prism:publicationName', 'prism:coverDate'}
                    if required_scopus_cols_nantes.issubset(scopus_df_raw_nantes.columns):
                        scopus_df_nantes = scopus_df_raw_nantes[['Data source', 'dc:title', 'prism:doi', 'dc:identifier', 'prism:publicationName', 'prism:coverDate']].copy()
                        scopus_df_nantes.columns = ['Data source', 'Title', 'doi', 'id', 'Source title', 'Date']
                        if 'doi' in scopus_df_nantes.columns:
                            scopus_df_nantes['doi'] = scopus_df_nantes['doi'].apply(clean_doi)
                    else:
                        st.warning(f"DonnÃ©es Scopus incomplÃ¨tes pour {collection_a_chercher_nantes}. Scopus sera ignorÃ©.")
                        scopus_df_nantes = pd.DataFrame()
                st.success(f"{len(scopus_df_nantes)} publications Scopus trouvÃ©es pour {collection_a_chercher_nantes}.")
        elif scopus_lab_id_nantes and not scopus_api_key_secret_nantes:
            st.warning(f"L'ID Scopus est fourni pour {collection_a_chercher_nantes} mais la clÃ© API Scopus n'est pas configurÃ©e. Scopus sera ignorÃ©.")
        progress_bar_nantes.progress(30) # CorrigÃ©
        
        # --- Ã‰tape 4 : Combinaison des donnÃ©es ---
        progress_text_area_nantes.info("Ã‰tape 4/9 : Combinaison des donnÃ©es sources...") # CorrigÃ©
        combined_df_nantes = pd.concat([scopus_df_nantes, openalex_df_nantes, pubmed_df_nantes], ignore_index=True)

        if combined_df_nantes.empty:
            st.error(f"Aucune publication rÃ©cupÃ©rÃ©e pour {collection_a_chercher_nantes}. VÃ©rifiez la configuration du laboratoire.")
            st.stop()
        
        if 'doi' not in combined_df_nantes.columns:
            combined_df_nantes['doi'] = pd.NA
        combined_df_nantes['doi'] = combined_df_nantes['doi'].astype(str).str.lower().str.strip().replace(['nan', 'none', 'NaN', ''], pd.NA, regex=False)


        # --- Ã‰tape 5 : Fusion des lignes en double ---
        progress_text_area_nantes.info("Ã‰tape 5/9 : Fusion des doublons...") # CorrigÃ©
        progress_bar_nantes.progress(40) # CorrigÃ©
        
        with_doi_df_nantes = combined_df_nantes[combined_df_nantes['doi'].notna()].copy()
        without_doi_df_nantes = combined_df_nantes[combined_df_nantes['doi'].isna()].copy()
        
        
        merged_data_doi_nantes = pd.DataFrame()
        if not with_doi_df_nantes.empty:
            merged_data_doi_nantes = with_doi_df_nantes.groupby('doi', as_index=False).apply(merge_rows_with_sources)
            if 'doi' not in merged_data_doi_nantes.columns and merged_data_doi_nantes.index.name == 'doi':
                merged_data_doi_nantes.reset_index(inplace=True)
            if isinstance(merged_data_doi_nantes.columns, pd.MultiIndex):
                 merged_data_doi_nantes.columns = merged_data_doi_nantes.columns.droplevel(0)
        
       
        merged_data_no_doi_nantes = pd.DataFrame()
        if not without_doi_df_nantes.empty:
            merged_data_no_doi_nantes = without_doi_df_nantes.copy() 
        
       
        final_merged_data_nantes = pd.concat([merged_data_doi_nantes, merged_data_no_doi_nantes], ignore_index=True)

        if final_merged_data_nantes.empty:
            st.error(f"Aucune donnÃ©e aprÃ¨s fusion pour {collection_a_chercher_nantes}.")
            st.stop()
        st.success(f"{len(final_merged_data_nantes)} publications uniques aprÃ¨s fusion pour {collection_a_chercher_nantes}.")
        progress_bar_nantes.progress(50) # CorrigÃ©

        # --- Ã‰tape 6 : Comparaison HAL ---
        coll_df_hal_nantes = pd.DataFrame()
        with st.spinner(f"Importation de la collection HAL '{collection_a_chercher_nantes}'..."):
            progress_text_area_nantes.info(f"Ã‰tape 6a/9 : Importation de la collection HAL '{collection_a_chercher_nantes}'...") # CorrigÃ©
            coll_importer_nantes_obj = HalCollImporter(collection_a_chercher_nantes, start_year_nantes, end_year_nantes)
            coll_df_hal_nantes = coll_importer_nantes_obj.import_data()
            if coll_df_hal_nantes.empty:
                st.warning(f"Collection HAL '{collection_a_chercher_nantes}' vide ou non chargÃ©e.")
            else:
                st.success(f"{len(coll_df_hal_nantes)} notices HAL pour {collection_a_chercher_nantes}.")
        
        progress_text_area_nantes.info("Ã‰tape 6b/9 : Comparaison avec les donnÃ©es HAL...") # CorrigÃ©
        result_df_nantes = check_df(final_merged_data_nantes.copy(), coll_df_hal_nantes, progress_bar_st=progress_bar_nantes, progress_text_st=progress_text_area_nantes) # PassÃ© les bons objets
        st.success(f"Comparaison HAL pour {collection_a_chercher_nantes} terminÃ©e.")
        # progress_bar_nantes est gÃ©rÃ© par check_df

        # --- Ã‰tape 7 : Enrichissement Unpaywall ---
        with st.spinner(f"Enrichissement Unpaywall pour {collection_a_chercher_nantes}..."):
            progress_text_area_nantes.info("Ã‰tape 7/9 : Enrichissement Unpaywall...") # CorrigÃ©
            progress_bar_nantes.progress(70) # CorrigÃ© (ajoutÃ© avant l'appel)
            result_df_nantes = enrich_w_upw_parallel(result_df_nantes.copy())
            st.success(f"Enrichissement Unpaywall pour {collection_a_chercher_nantes} terminÃ©.")
        # progress_bar_nantes.progress(70) # DÃ©placÃ© avant l'appel

        # --- Ã‰tape 8 : Permissions de dÃ©pÃ´t ---
        with st.spinner(f"RÃ©cupÃ©ration des permissions pour {collection_a_chercher_nantes}..."):
            progress_text_area_nantes.info("Ã‰tape 8/9 : RÃ©cupÃ©ration des permissions de dÃ©pÃ´t...") # CorrigÃ©
            progress_bar_nantes.progress(80) # CorrigÃ© (ajoutÃ© avant l'appel)
            result_df_nantes = add_permissions_parallel(result_df_nantes.copy())
            st.success(f"Permissions pour {collection_a_chercher_nantes} rÃ©cupÃ©rÃ©es.")
        # progress_bar_nantes.progress(80) # DÃ©placÃ© avant l'appel

        # --- Ã‰tape 9 : DÃ©duction des actions et auteurs ---
        progress_text_area_nantes.info("Ã‰tape 9/9 : DÃ©duction des actions et traitement des auteurs...") # CorrigÃ©
        if 'Action' not in result_df_nantes.columns: result_df_nantes['Action'] = pd.NA
        result_df_nantes['Action'] = result_df_nantes.apply(deduce_todo, axis=1)

        if fetch_authors_nantes: 
            with st.spinner(f"RÃ©cupÃ©ration des auteurs Crossref pour {collection_a_chercher_nantes}..."):
                if 'doi' in result_df_nantes.columns:
                    from concurrent.futures import ThreadPoolExecutor 
                    from tqdm import tqdm 

                    dois_for_authors_nantes = result_df_nantes['doi'].fillna("").tolist()
                    authors_results_nantes = []
                    with ThreadPoolExecutor(max_workers=10) as executor:
                        authors_results_nantes = list(tqdm(executor.map(get_authors_from_crossref, dois_for_authors_nantes), total=len(dois_for_authors_nantes), desc="Auteurs Crossref (Nantes)"))
                    
                    result_df_nantes['Auteurs_Crossref'] = ['; '.join(author_l) if isinstance(author_l, list) and not any("Erreur" in str(a) or "Timeout" in str(a) for a in author_l) else (author_l[0] if isinstance(author_l, list) and author_l else '') for author_l in authors_results_nantes]
                    st.success(f"Auteurs Crossref pour {collection_a_chercher_nantes} rÃ©cupÃ©rÃ©s.")
                else:
                    st.warning("Colonne 'doi' non trouvÃ©e, impossible de rÃ©cupÃ©rer les auteurs pour la version Nantes.")
                    result_df_nantes['Auteurs_Crossref'] = ''
            
            if compare_authors_nantes and uploaded_authors_file_nantes:
                with st.spinner(f"Comparaison des auteurs (fichier) pour {collection_a_chercher_nantes}..."):
                    try:
                        user_authors_df_nantes_file = pd.read_csv(uploaded_authors_file_nantes)
                        if not ({'collection', user_authors_df_nantes_file.columns[1]} <= set(user_authors_df_nantes_file.columns)):
                            st.error("Fichier CSV auteurs mal formatÃ© pour la version Nantes.")
                        else:
                            author_name_col_nantes_file = user_authors_df_nantes_file.columns[1]
                            noms_ref_nantes_list = user_authors_df_nantes_file[user_authors_df_nantes_file["collection"].astype(str).str.lower() == str(collection_a_chercher_nantes).lower()][author_name_col_nantes_file].dropna().unique().tolist()
                            if not noms_ref_nantes_list:
                                st.warning(f"Aucun chercheur pour '{collection_a_chercher_nantes}' dans le fichier fourni (Nantes).")
                            else:
                                chercheur_map_nantes_file = {normalize_name(n): n for n in noms_ref_nantes_list}
                                initial_map_nantes_file = {get_initial_form(normalize_name(n)): n for n in noms_ref_nantes_list}
                                from difflib import get_close_matches 

                                def detect_known_authors_nantes_file(authors_str_nantes):
                                    if pd.isna(authors_str_nantes) or not str(authors_str_nantes).strip() or "Erreur" in authors_str_nantes or "Timeout" in authors_str_nantes: return ""
                                    authors_pub_nantes = [a.strip() for a in str(authors_str_nantes).split(';') if a.strip()]
                                    detectes_originaux_nantes = set()
                                    for author_o_nantes in authors_pub_nantes:
                                        author_n_nantes = normalize_name(author_o_nantes)
                                        author_i_n_nantes = get_initial_form(author_n_nantes)
                                        match_c_nantes = get_close_matches(author_n_nantes, chercheur_map_nantes_file.keys(), n=1, cutoff=0.85)
                                        if match_c_nantes:
                                            detectes_originaux_nantes.add(chercheur_map_nantes_file[match_c_nantes[0]])
                                            continue
                                        match_i_nantes = get_close_matches(author_i_n_nantes, initial_map_nantes_file.keys(), n=1, cutoff=0.9)
                                        if match_i_nantes:
                                            detectes_originaux_nantes.add(initial_map_nantes_file[match_i_nantes[0]])
                                    return "; ".join(sorted(list(detectes_originaux_nantes))) if detectes_originaux_nantes else ""
                                result_df_nantes['Auteurs_Laboratoire_DÃ©tectÃ©s'] = result_df_nantes['Auteurs_Crossref'].apply(detect_known_authors_nantes_file)
                                st.success(f"Comparaison auteurs (fichier) pour {collection_a_chercher_nantes} terminÃ©e.")
                    except Exception as e_auth_file_nantes_exc:
                        st.error(f"Erreur fichier auteurs (Nantes): {e_auth_file_nantes_exc}")
            elif compare_authors_nantes and not uploaded_authors_file_nantes:
                 st.warning("Veuillez tÃ©lÃ©verser un fichier CSV de chercheurs pour la comparaison des auteurs (Nantes).")

        progress_bar_nantes.progress(90) # CorrigÃ©
        st.success(f"DÃ©duction des actions et traitement des auteurs pour {collection_a_chercher_nantes} terminÃ©s.")
        
        st.dataframe(result_df_nantes)

        if not result_df_nantes.empty:
            csv_export_nantes_data = result_df_nantes.to_csv(index=False, encoding='utf-8-sig')
            output_filename_nantes_final = f"c2LabHAL_resultats_{collection_a_chercher_nantes.replace(' ', '_')}_{start_year_nantes}-{end_year_nantes}.csv"
            st.download_button(
                label=f"ðŸ“¥ TÃ©lÃ©charger les rÃ©sultats pour {collection_a_chercher_nantes}",
                data=csv_export_nantes_data,
                file_name=output_filename_nantes_final,
                mime="text/csv",
                key=f"download_nantes_{collection_a_chercher_nantes}"
            )
        progress_bar_nantes.progress(100) # CorrigÃ©
        progress_text_area_nantes.success(f"ðŸŽ‰ Traitement pour {collection_a_chercher_nantes} terminÃ© avec succÃ¨s !") # CorrigÃ©

if __name__ == "__main__":
    main()