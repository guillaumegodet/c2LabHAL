import requests
import pandas as pd
import time
import streamlit as st
from urllib.parse import urlencode

# Le point d'entr√©e de l'API de recherche HAL pour les documents
HAL_SEARCH_API = "http://api.archives-ouvertes.fr/search/"
# Le point d'entr√©e de l'API de r√©f√©rence HAL pour les auteurs (pour les d√©tails)
HAL_AUTHOR_API = "http://api.archives-ouvertes.fr/ref/author/"

# --- Fonctions d'extraction HAL (Adapt√©es √† la Collection) ---

def fetch_publications_for_collection(collection_code, years="", fields="structHasAuthId_fs"):
    """
    R√©cup√®re tous les documents (publications) pour un code de collection donn√©
    en utilisant l'API de recherche HAL.
    """
    all_docs = []
    rows = 10000  # Nombre maximal de documents par requ√™te
    start = 0
    
    # La requ√™te utilise le code de collection dans le chemin de l'URL
    query_params = {
        'q': '*:*',
        'wt': 'json',
        'fl': fields,
        'rows': rows
    }

    if years:
        query_params['fq'] = f'producedDateY_i:{years}'
        
    st.toast(f"D√©marrage de la r√©cup√©ration pour la collection '{collection_code}' (Ann√©e(s): {years if years else 'Toutes'})")

    while True:
        query_params['start'] = start
        
        # URL de l'API de recherche HAL, avec le code de collection dans le chemin
        url = f"{HAL_SEARCH_API}{collection_code}/?{urlencode(query_params)}"
        
        try:
            response = requests.get(url)
            response.raise_for_status()
            data = response.json()
            
            docs = data.get('response', {}).get('docs', [])
            num_found = data.get('response', {}).get('numFound', 0)
            all_docs.extend(docs)
            
            found_publications = len(all_docs)
            
            # --- DEBUG ---
            if start == 0:
                print(f"DEBUG: Requ√™te initiale pour publications. Nombre total trouv√© (numFound): {num_found}")
            # -------------

            if found_publications >= num_found or not docs:
                break
            
            start += rows
            time.sleep(0.5) 

        except requests.exceptions.RequestException as e:
            st.error(f"Erreur lors de la requ√™te API (Recherche publications): {e}")
            break
            
    return all_docs

def extract_author_ids(publications):
    """
    Extrait les identifiants uniques des formes-auteurs (docid du r√©f√©rentiel auteur)
    √† partir de la liste des publications, en ne conservant que l'ID num√©rique final
    et en ignorant les auteurs sans forme-auteur (ID terminant par -0).
    """
    author_ids = set()
    for doc in publications:
        authors = doc.get('structHasAuthId_fs', [])
        for author_str in authors:
            # Le format est typiquement "STRUCTID_HALID_JoinSep_AUTHORID_FacetSep"
            parts = author_str.split('_JoinSep_')
            if len(parts) > 1:
                # Capture de l'ID sous forme HALID-DOCID (ex: "1188340-1286042" ou "1792468-0")
                full_author_id = parts[1].split('_FacetSep')[0]
                
                # --- CORRECTION: Extraire uniquement le DOCID num√©rique final ---
                docid_parts = full_author_id.split('-')
                
                # On prend la derni√®re partie de l'ID. Ex: "1286042" pour "1188340-1286042"
                docid = docid_parts[-1]
                
                # On s'assure que le DOCID n'est pas "0" (auteur sans forme/r√©f√©rentiel)
                if docid.isdigit() and docid != "0":
                    author_ids.add(docid)
                # --------------------------------------------------------------
                
    return list(author_ids)

def fetch_author_details(author_ids, fields):
    """
    R√©cup√®re les d√©tails de chaque forme-auteur (par son docid)
    en utilisant l'API de r√©f√©rence HAL, en interrogeant par lots (chunk) 
    via le champ `person_i`.
    """
    authors_details = []
    chunk_size = 5 
    total_authors = len(author_ids)
    
    st.toast(f"R√©cup√©ration des d√©tails pour {total_authors} formes-auteurs (Requ√™te par lots via person_i)...")
    
    progress_bar = st.progress(0, text="0% - R√©cup√©ration des d√©tails auteurs...")

    for i in range(0, total_authors, chunk_size):
        chunk = author_ids[i:i + chunk_size]
        
        # --- CORRECTION APPLIQU√âE : Utilisation de person_i au lieu de docid ---
        # Construction de la requ√™te Solr pour les person_i
        person_i_query = '%22 OR person_i:%22'.join(chunk)
        
        query_params = {
            'q': f'person_i:"{person_i_query}"',
            'wt': 'json',
            'fl': fields
        }
        # --------------------------------------------------------------------------
        
        url = f"{HAL_AUTHOR_API}?{urlencode(query_params)}"
        
        try:
            response = requests.get(url)
            response.raise_for_status()
            data = response.json()
            
            docs = data.get('response', {}).get('docs', [])
            
            # --- DEBUG ---
            print(f"DEBUG: Lot {i}/{total_authors}. Tentative: {len(chunk)} IDs. Re√ßus: {len(docs)} documents.")
            # -------------
            
            # Application de la logique de transformation du statut de validation
            for doc in docs:
                if 'valid_s' in doc:
                    validity_status = doc['valid_s']
                    if validity_status == "VALID":
                        doc['valid_s'] = "forme auteur principale d'un IdHAL"
                    elif validity_status == "OLD":
                        doc['valid_s'] = "forme auteur alternative d'un IdHAL"
                    elif validity_status == "INCOMING":
                        doc['valid_s'] = "forme auteur sans IdHAL associ√©"
                authors_details.append(doc)

            # Mise √† jour de la barre de progression
            progress_percent = (i + len(chunk)) / total_authors
            progress_bar.progress(progress_percent, text=f"{int(progress_percent * 100)}% - Lots trait√©s.")

            # Petite pause pour respecter les limites de l'API
            time.sleep(0.3) 

        except requests.exceptions.RequestException as e:
            st.error(f"Erreur lors de la requ√™te API (D√©tails Auteur pour le lot {i} √† {i+len(chunk)}): {e}")
            # --- DEBUG ---
            print(f"DEBUG: ERREUR NON FATALE rencontr√©e pour le lot {i}. D√©tails: {e}. Continue vers le lot suivant.")
            # -------------
            continue # Passe au lot suivant en cas d'erreur
            
    progress_bar.empty()
    return authors_details

def get_all_author_forms_data(collection_code, years="", fields_list="docid,fullName_s,valid_s,halId_s,orcidId_s,firstName_s,lastName_s"):
    """
    Fonction principale pour orchestrer l'extraction de TOUTES les formes-auteurs 
    (sans d√©duplication) pour une collection.
    """
    
    # 1. R√©cup√©rer les publications et les identifiants d'auteurs
    publications = fetch_publications_for_collection(collection_code, years)
    if not publications:
        st.warning("Aucune publication trouv√©e pour la collection et l'ann√©e(s) sp√©cifi√©es.")
        return pd.DataFrame()
        
    author_ids = extract_author_ids(publications)
    
    # --- DEBUG ---
    print(f"DEBUG: Nombre total de publications trouv√©es : {len(publications)}")
    print(f"DEBUG: Nombre total d'IDs de formes-auteurs (docid) extraits : {len(author_ids)}")
    # -------------

    if not author_ids:
        st.info("Aucune forme-auteur (docid) valide n'a pu √™tre extraite des publications trouv√©es.")
        return pd.DataFrame()

    # 2. R√©cup√©rer les d√©tails des auteurs (formes-auteurs)
    author_details = fetch_author_details(author_ids, fields_list)
    
    # --- DEBUG ---
    print(f"DEBUG: Nombre final de documents re√ßus du r√©f√©rentiel auteur : {len(author_details)}")
    # -------------

    if not author_details:
        st.warning("Aucun d√©tail d'auteur n'a pu √™tre r√©cup√©r√© de l'API de r√©f√©rence. (L'erreur s'est probablement produite ici.)")
        return pd.DataFrame()

    # 3. Cr√©er le DataFrame final (pas de d√©duplication)
    df = pd.DataFrame(author_details)
    
    # S'assurer que les colonnes sont dans l'ordre demand√©
    requested_fields = fields_list.split(',')
    final_cols = [col for col in requested_fields if col in df.columns]
    
    return df[final_cols]

# --- Fonctions utilitaires pour Streamlit ---
@st.cache_data
def convert_df(df):
    """Convertit un DataFrame en CSV pour le t√©l√©chargement."""
    # Utilisation du point-virgule comme s√©parateur pour la compatibilit√© Excel en fran√ßais
    return df.to_csv(index=False, sep=';').encode('utf-8')

def build_fields_list(fields_selected):
    """Construit la cha√Æne de champs √† partir des s√©lections Streamlit."""
    # Ajoute les champs obligatoires pour l'affichage
    mandatory_fields = ['docid', 'fullName_s', 'valid_s']
    
    final_fields = list(set(mandatory_fields + fields_selected))
    
    return ','.join(final_fields)

# --- Application Streamlit ---
def main():
    st.set_page_config(page_title="Extracteur Formes-Auteurs HAL (Collection)", layout="wide")
    st.title("Extracteur de Formes-Auteurs par Collection HAL")
    st.markdown("Extrait **toutes les formes-auteurs** rattach√©es aux publications de la collection. Utile pour l'identification des doublons.")
    st.markdown("---")

    # Options des champs (similaire aux champs courants du r√©f√©rentiel)
    all_available_fields = [
        'halId_s', 'orcidId_s', 'firstName_s', 'lastName_s', 
        'email_s', 'hasCV_bool', 'birthDateY_i'
    ]
    
    with st.sidebar:
        st.header("Param√®tres de l'Extraction")
        collection_code = st.text_input("Code Collection HAL (ex: CRAO, LEMNA)", value="LEMNA")
        years = st.text_input("P√©riode vis√©e (ex: 2023, [2016 TO 2018])", value="2024")
        
        st.subheader("Champs d'Auteur √† R√©cup√©rer")
        
        default_fields = ['halId_s', 'orcidId_s', 'firstName_s', 'lastName_s']
        
        fields_selected = st.multiselect(
            "S√©lectionnez les champs additionnels (le 'docid' est l'ID de la forme-auteur)", 
            options=all_available_fields,
            default=default_fields
        )
        
        # Bouton d'extraction
        if st.button("Lancer l'Extraction", type="primary"):
            if not collection_code:
                st.sidebar.error("Veuillez entrer un code de collection HAL.")
                return
            
            # Pr√©parer les champs pour l'API
            api_fields = build_fields_list(fields_selected)
            
            with st.spinner(f"R√©cup√©ration en cours pour la collection **{collection_code}**..."):
                # Ex√©cution de la logique d'extraction sans d√©duplication
                df_authors = get_all_author_forms_data(collection_code, years, api_fields)
            
            if df_authors.empty:
                # La gestion des messages d'erreur se fait dans get_all_author_forms_data
                pass 
            else:
                st.session_state['df_authors'] = df_authors
                st.session_state['collection_code'] = collection_code
                st.session_state['years'] = years

    # --- Affichage des r√©sultats ---
    if 'df_authors' in st.session_state and not st.session_state['df_authors'].empty:
        df_authors = st.session_state['df_authors']
        collection_code = st.session_state['collection_code']
        years = st.session_state['years']
        
        st.subheader(f"R√©sultats pour Collection : **{collection_code}** ({'Ann√©e(s) : **' + years + '**' if years else '**Toutes ann√©es**'})")
        
        # L'affichage des doublons est utile pour rep√©rer les doublons par nom
        df_display = df_authors.sort_values(by='fullName_s') 
        
        st.info(f"Nombre total de **formes-auteurs** trouv√©es : **{len(df_authors)}**")
        st.markdown("_Les lignes ayant le m√™me `fullName_s` mais un `docid` (ID de forme-auteur) diff√©rent sont des doublons potentiels. V√©rifiez la console pour le statut de chaque lot d'auteurs r√©cup√©r√©._")
        
        # Afficher le DataFrame
        st.dataframe(df_display, use_container_width=True)
        
        # Pr√©parer et afficher le bouton de t√©l√©chargement CSV
        csv_data = convert_df(df_authors)
        filename = f'toutes_formes_auteurs_{collection_code}_{years.replace(" ", "_") if years else "all"}.csv'
        
        st.download_button(
            label="üíæ T√©l√©charger la liste de TOUTES les formes-auteurs (CSV)",
            data=csv_data,
            file_name=filename,
            mime='text/csv',
            key='download_button'
        )
        st.markdown("_Le s√©parateur est le point-virgule (`;`) pour Excel._")

if __name__ == '__main__':
    main()
